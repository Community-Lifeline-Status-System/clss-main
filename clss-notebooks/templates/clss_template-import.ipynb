{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLSS Template Import Process\n",
    "\n",
    "This notebook is designed to import CLSS templates and related data from specified files into the ArcGIS Online feature services. The imported data can be used to update or initialize the CLSS feature services with the latest templates and configurations.\n",
    "\n",
    "#### Prerequisites\n",
    "Before running this notebook, please ensure the following:\n",
    "\n",
    "1. **Export Process**:  Before running the CLSS Template Import process, you must first use the 'template-export' notebook to export the CLSS templates. The exported templates (csv files) must be saved to the `/home/export` folder.\n",
    "\n",
    "#### Steps\n",
    "1. **Select Feature Service**: Use the dropdown menu to select the target CLSS feature service for importing the templates.\n",
    "2. **Import Data**: The notebook will import the CLSS templates and related data into the selected feature service.\n",
    "3. **Save Imported Data**: The imported data will be saved in the feature service for further use.\n",
    "\n",
    "\n",
    "#### Links\n",
    "- [DevOps Story #1779](https://dev.azure.com/ghinternational/GHIS/_workitems/edit/1779)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies & set key variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Third-party library imports\n",
    "import pandas as pd\n",
    "from arcgis.gis import GIS\n",
    "import ipywidgets as widgets\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "\n",
    "### if target_feature_service_id is None, the script will let the user pick from a list of feature services \n",
    "### in the org matching search term\n",
    "\n",
    "\n",
    "# target_feature_service_id = '980b62dffcb94c10bff227e9a8a43fce'  # Replace with the actual target feature service ID\n",
    "target_feature_service_id = 'None'\n",
    "clss_search_term = 'title: CLSS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current date-time\n",
    "current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# Check if /home folder exists, if not create it\n",
    "home_dir = 'home'\n",
    "if not os.path.exists(home_dir):\n",
    "    os.makedirs(home_dir)\n",
    "\n",
    "# Check if ../export folder exists, if not create it\n",
    "export_dir = f'{home_dir}/export'\n",
    "if not os.path.exists(export_dir):\n",
    "    os.makedirs(export_dir)\n",
    "\n",
    "# gis = GIS(\"home\")\n",
    "# Following section not needed when signing in via ArcGIS Online Notebook\n",
    "# Get username and password from config file \n",
    "with open(f'{home_dir}/config.json') as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "AGO_username = config['AGO_username']\n",
    "AGO_password = config['AGO_password']\n",
    "\n",
    "# Sign into the ArcGIS Online or Enterprise Portal\n",
    "gis = GIS(\"https://ghis.maps.arcgis.com/\", AGO_username, AGO_password)\n",
    "\n",
    "# These are the CLSS ArcGIS online Service Endpoints \n",
    "clssServices = [('None', 'None'),  # Example ID for Dev\n",
    "             ('CLSS Dev', '4cec9a93384543e0a676e3ad892362bb'),  \n",
    "             ('CLSS Test', 'f726c24e77d5442c9a9f456eec62ae5d'),  \n",
    "             ('CLSS Demo', 'c5aea531e01d49358b73123e334b4c0a')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a70cc9aaa29a43d783a43de585adf8aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Select Service:', options=('None', 'CLSS_FeatureService_Tst 2025_05', 'CLSS_Lucky_Gulch_â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "if target_feature_service_id == 'None':\n",
    "    # Search for feature services containing 'CLSS' in their name\n",
    "    search_results = gis.content.search(query=clss_search_term, \n",
    "                                        item_type=\"Feature Service\", \n",
    "                                        max_items=50, \n",
    "                                        sort_field=\"modified\", \n",
    "                                        sort_order=\"desc\")\n",
    "\n",
    "    # Create a dictionary of search results with title as key and id as value\n",
    "    clss_feature_services = {item.title: item.id for item in search_results}\n",
    "\n",
    "    # Create a dropdown widget for selecting the feature service\n",
    "    feature_service_choice = widgets.Dropdown(\n",
    "        options=['None'] + list(clss_feature_services.keys()),\n",
    "        description='Select Service:',\n",
    "        disabled=False,\n",
    "    )\n",
    "\n",
    "    # Display the dropdown widget\n",
    "    display(feature_service_choice)\n",
    "\n",
    "    # Function to handle the feature service selection\n",
    "    def on_feature_service_selected(change):\n",
    "        global target_feature_service_id \n",
    "        global target_feature_service\n",
    "        selected_service = change['new']\n",
    "        if selected_service != 'None':\n",
    "            target_feature_service_id = clss_feature_services[selected_service]\n",
    "            print(f\"Selected feature service ID: {target_feature_service_id}\")\n",
    "            target_feature_service = gis.content.get(target_feature_service_id)\n",
    "\n",
    "\n",
    "    # Attach the handler to the dropdown widget\n",
    "    feature_service_choice.observe(on_feature_service_selected, names='value')\n",
    "\n",
    "else:\n",
    "    print(f\"Using target feature service ID: {target_feature_service_id}\")\n",
    "    target_feature_service = gis.content.get(target_feature_service_id)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required tables and layers found in the feature service.\n"
     ]
    }
   ],
   "source": [
    "target_hazards_table = None\n",
    "target_template_table = None    \n",
    "target_org_lyr = None\n",
    "# Loop through the tables and layers to find the required ones\n",
    "for table in target_feature_service.tables:\n",
    "    if (table.properties.name == 'Hazard'):\n",
    "        target_hazards_table = table\n",
    "    if (table.properties.name == 'Template'):\n",
    "        target_template_table = table\n",
    "\n",
    "for layer in target_feature_service.layers:\n",
    "    if (layer.properties.name == 'Organization'):\n",
    "        target_org_lyr = layer\n",
    "# Check if the required tables and layers were found\n",
    "\n",
    "if target_hazards_table is None or target_template_table is None or target_org_lyr is None:\n",
    "    raise ValueError(\"Required tables and layers not found in the feature service.\")\n",
    "else:\n",
    "    print(\"Required tables and layers found in the feature service.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FeatureLayer url:\"https://services3.arcgis.com/j2a3SeWN04oskFYa/arcgis/rest/services/CLSS_FeatureService_Tst_2025_05/FeatureServer/2\">"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_org_lyr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_indicator_json(template_indicator_df):\n",
    "    # Create JSON representation of template_info_df\n",
    "    template_json = []\n",
    "    for lifeline, lifeline_group in template_indicator_df.groupby('Lifeline'):\n",
    "        lifeline_dict = {\n",
    "            \"name\": lifeline,\n",
    "            \"title\": lifeline,\n",
    "            \"componentTemplates\": []\n",
    "        }\n",
    "        for component, component_group in lifeline_group.groupby('Component'):\n",
    "            component_dict = {\n",
    "                \"name\": component,\n",
    "                \"title\": component,\n",
    "                \"indicators\": []\n",
    "            }\n",
    "            for _, row in component_group.iterrows():\n",
    "                indicator_dict = {\n",
    "                    \"name\": row['Indicator'],\n",
    "                    \"templateName\": \"Template Name\",\n",
    "                    \"lifelineName\": lifeline,\n",
    "                    \"componentName\": component,\n",
    "                    \"weight\": row['Weight']\n",
    "                }\n",
    "                component_dict[\"indicators\"].append(indicator_dict)\n",
    "            lifeline_dict[\"componentTemplates\"].append(component_dict)\n",
    "        template_json.append(lifeline_dict)\n",
    "    return template_json\n",
    "\n",
    "def add_to_feature_service(template_info_df, template_json):\n",
    "    #### Working - add template\n",
    "    global df\n",
    "    df = template_info_df.rename(columns={\n",
    "        'Template Name': 'Name',\n",
    "        'Template Description': 'Description',\n",
    "        'Status': 'Status',\n",
    "        'HazardName': 'HazardID',  # Placeholder until we assign actual ID\n",
    "        'OrganizationName': 'OrganizationID',  # Placeholder until we assign actual ID\n",
    "    })\n",
    "    try:\n",
    "        df = df.drop(columns=['CreationDate', 'EditDate']).fillna('N/A') \n",
    "    except KeyError:\n",
    "        print(\"Columns 'CreationDate' and 'EditDate' do not exist in the DataFrame.\")\n",
    "    \n",
    "    # Add 'Content' column to the DataFrame and populate it with template_json\n",
    "    df['Content'] = json.dumps(template_json, ensure_ascii=False)\n",
    "\n",
    "    # Query Hazards Table - see if any hazards match HazardName field. If not, add new Hazard to Hazards table and get GlobalID.\n",
    "    # Get raw values from the original template_info_df (unrenamed)\n",
    "    hazardName = str(template_info_df['HazardName'].iloc[0]).strip()\n",
    "    orgName = str(template_info_df['OrganizationName'].iloc[0]).strip()\n",
    "\n",
    "    # Validate if they are usable (i.e., not blank or 'N/A')\n",
    "    valid_hazard = hazardName and hazardName.upper() != 'N/A'\n",
    "    valid_org = orgName and orgName.upper() != 'N/A'\n",
    "\n",
    "    df['HazardID'] = getHazard(hazardName, target_hazards_table) if valid_hazard else ''\n",
    "    df['OrganizationID'] = getOrg(orgName, target_org_lyr) if valid_org else ''\n",
    "\n",
    "    # Convert the DataFrame to a list of dictionary features adhering to ArcGIS feature JSON structure\n",
    "    for _, row in df.iterrows():\n",
    "        if len(str(row['OrganizationID'])) > 1:\n",
    "            features = {\n",
    "                \"attributes\": {\n",
    "                    \"OrganizationID\": row['OrganizationID'],\n",
    "                    \"HazardID\": row['HazardID'],\n",
    "                    \"Name\": row['Name'],\n",
    "                    \"Description\": row['Description'],\n",
    "                    \"Status\": row['Status'],\n",
    "                    # \"IsDeleted\": row['IsDeleted'],\n",
    "                    \"Content\": json.dumps(template_json, ensure_ascii=True).replace('\"', '\\\\\"')\n",
    "                }\n",
    "            }\n",
    "        else:\n",
    "            features = {\n",
    "                \"attributes\": {\n",
    "                    \"HazardID\": row['HazardID'],\n",
    "                    \"Name\": row['Name'],\n",
    "                    \"Description\": row['Description'],\n",
    "                    \"Status\": row['Status'],\n",
    "                    # \"IsDeleted\": row['IsDeleted'],\n",
    "                    \"Content\": json.dumps(template_json, ensure_ascii=True).replace('\"', '\\\\\"')\n",
    "                }\n",
    "            }\n",
    "\n",
    "    # Add the features to the target template table\n",
    "    try:\n",
    "        response = target_template_table.edit_features(adds=[features])\n",
    "        print(f'Successfully uploaded template to feature service: {target_feature_service.title}')\n",
    "    except Exception as e:\n",
    "        print(f'Error uploading CSV to feature service: {e}')\n",
    "\n",
    "# Query the hazards table to check if the hazardName exists\n",
    "def getHazard(hazName, target_hazards_table):\n",
    "    print('getHazard:',hazName)\n",
    "    try:\n",
    "        query_result = target_hazards_table.query(where=f\"Name='{hazName}'\")\n",
    "        hazard_global_id = query_result.features[0].attributes['GlobalID']\n",
    "    except:\n",
    "        new_hazard = {\n",
    "            \"attributes\": {\n",
    "                \"Name\": hazName,\n",
    "                \"Description\": \"Added by script\",\n",
    "                \"Status\": 1,\n",
    "                \"IsDeleted\": 0\n",
    "            }\n",
    "        }\n",
    "        add_result = target_hazards_table.edit_features(adds=[new_hazard])\n",
    "        if add_result['addResults'][0]['success']:\n",
    "            hazard_global_id = add_result['addResults'][0]['globalId']\n",
    "        else:\n",
    "            raise RuntimeError(\"Failed to add new hazard to the hazards table\")\n",
    "\n",
    "    return hazard_global_id\n",
    "\n",
    "\n",
    "# Query the Org layer to check if the hazardName exists\n",
    "def getOrg(orgName, target_org_lyr):\n",
    "    if pd.isna(orgName) or str(orgName).strip() == '':\n",
    "        raise ValueError(\"OrganizationName is missing or invalid\")\n",
    "\n",
    "    orgName_safe = str(orgName).replace(\"'\", \"''\")\n",
    "    query_result = target_org_lyr.query(where=f\"Name='{orgName_safe}'\")\n",
    "\n",
    "    if query_result.features:\n",
    "        org_global_id = query_result.features[0].attributes['GlobalID']\n",
    "    else:\n",
    "        print(f\"No org found for '{orgName}' â€” adding new one.\")\n",
    "        new_org = {\n",
    "            \"attributes\": {\n",
    "                \"Name\": orgName,\n",
    "                \"Description\": \"Added by script\",\n",
    "                \"Status\": 1,\n",
    "                \"IsDeleted\": 0\n",
    "            }\n",
    "        }\n",
    "        add_result = target_org_lyr.edit_features(adds=[new_org])\n",
    "        if add_result['addResults'][0]['success']:\n",
    "            org_global_id = add_result['addResults'][0]['globalId']\n",
    "            print(f\"Added new org '{orgName}', GlobalID: {org_global_id}\")\n",
    "        else:\n",
    "            raise RuntimeError(\"Failed to add new organization to the org layer\")\n",
    "\n",
    "    return org_global_id\n",
    "\n",
    "# Function to handle the CSV file selection\n",
    "def on_csv_selected(change):\n",
    "    global csv_file_path, template_info, template_df\n",
    "    csv_file_path = os.path.join(export_dir, change['new'])\n",
    "    template_info = csv_file_path\n",
    "    template_df = pd.read_csv(template_info, sep=',', quoting=1)\n",
    "\n",
    "    print(f\"Selected template  file: {template_info}\")\n",
    "\n",
    "    indicator_json = return_indicator_json(template_df)\n",
    "    print(indicator_json)\n",
    "    add_to_feature_service(template_df, indicator_json)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Template Export Files\n",
    "process template files and import into destination feature service\n",
    "\n",
    "User selects CSV\n",
    "   â†“\n",
    "\n",
    "on_csv_selected()\n",
    "   â†“\n",
    "\n",
    "Read CSV â†’ template_df\n",
    "   â†“\n",
    "\n",
    "return_indicator_json(template_df) â”€â”€> indicator_json\n",
    "   â†“\n",
    "   \n",
    "add_to_feature_service(template_df, indicator_json)\n",
    "   â”œâ”€â”€ Clean/Rename columns\n",
    "   â”œâ”€â”€ Lookup HazardID (getHazard)\n",
    "   â”œâ”€â”€ Lookup OrgID (getOrg)\n",
    "   â”œâ”€â”€ Build ArcGIS feature\n",
    "   â””â”€â”€ Submit via edit_features()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1813201d8f9d4f46aae3e4802daeb067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bd504a2464d47c48acccfdba6ec74f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Select CSV:', options=('None', 'CLSS_FeatureService_Dev_ACA Earthquake Template_Indicatoâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = widgets.Output()\n",
    "display(output)\n",
    "\n",
    "# List CSV files in the 'export' folder\n",
    "csv_files = [f for f in os.listdir(export_dir) if f.endswith('.csv')]\n",
    "\n",
    "# Create a dropdown widget for selecting the CSV file\n",
    "csv_file_choice = widgets.Dropdown(\n",
    "    options=['None'] + csv_files,\n",
    "    description='Select CSV:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "\n",
    "# Display the dropdown widget & attach the handler\n",
    "display(csv_file_choice)\n",
    "csv_file_choice.observe(on_csv_selected, names='value')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Table url:\"https://services3.arcgis.com/j2a3SeWN04oskFYa/arcgis/rest/services/CLSS_FeatureService_Tst_2025_05/FeatureServer/4\">"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_hazards_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
